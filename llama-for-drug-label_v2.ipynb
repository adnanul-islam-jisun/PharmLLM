{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6c8229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:38:22.450209Z",
     "iopub.status.busy": "2025-01-22T04:38:22.449958Z",
     "iopub.status.idle": "2025-01-22T04:38:54.649400Z",
     "shell.execute_reply": "2025-01-22T04:38:54.648279Z"
    },
    "papermill": {
     "duration": 32.206462,
     "end_time": "2025-01-22T04:38:54.651411",
     "exception": false,
     "start_time": "2025-01-22T04:38:22.444949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U accelerate peft bitsandbytes transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff5705c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:38:54.660579Z",
     "iopub.status.busy": "2025-01-22T04:38:54.660285Z",
     "iopub.status.idle": "2025-01-22T04:39:26.396561Z",
     "shell.execute_reply": "2025-01-22T04:39:26.395896Z"
    },
    "papermill": {
     "duration": 31.742873,
     "end_time": "2025-01-22T04:39:26.398419",
     "exception": false,
     "start_time": "2025-01-22T04:38:54.655546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 04:39:09.505495: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-22 04:39:09.505656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-22 04:39:09.764834: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    Trainer\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687c923c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:26.407299Z",
     "iopub.status.busy": "2025-01-22T04:39:26.407031Z",
     "iopub.status.idle": "2025-01-22T04:39:26.410510Z",
     "shell.execute_reply": "2025-01-22T04:39:26.409772Z"
    },
    "papermill": {
     "duration": 0.009571,
     "end_time": "2025-01-22T04:39:26.412077",
     "exception": false,
     "start_time": "2025-01-22T04:39:26.402506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = \"/kaggle/input/llama-3.2/transformers/1b-instruct/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1199c179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:26.420240Z",
     "iopub.status.busy": "2025-01-22T04:39:26.419824Z",
     "iopub.status.idle": "2025-01-22T04:39:26.541843Z",
     "shell.execute_reply": "2025-01-22T04:39:26.540767Z"
    },
    "papermill": {
     "duration": 0.128015,
     "end_time": "2025-01-22T04:39:26.543660",
     "exception": false,
     "start_time": "2025-01-22T04:39:26.415645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set torch dtype and attention implementation\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn\n",
    "    torch_dtype = torch.bfloat16\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "    print(\"cuda\")\n",
    "else:\n",
    "    torch_dtype = torch.float16\n",
    "    attn_implementation = \"eager\"\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4db07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:26.553013Z",
     "iopub.status.busy": "2025-01-22T04:39:26.552438Z",
     "iopub.status.idle": "2025-01-22T04:39:26.557436Z",
     "shell.execute_reply": "2025-01-22T04:39:26.556769Z"
    },
    "papermill": {
     "duration": 0.011346,
     "end_time": "2025-01-22T04:39:26.559047",
     "exception": false,
     "start_time": "2025-01-22T04:39:26.547701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# QLoRA config -- 4bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# # Load model\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     base_model,\n",
    "#     quantization_config=bnb_config,\n",
    "#     device_map=\"auto\",\n",
    "#     attn_implementation=attn_implementation\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42439f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:26.568361Z",
     "iopub.status.busy": "2025-01-22T04:39:26.567770Z",
     "iopub.status.idle": "2025-01-22T04:39:48.654000Z",
     "shell.execute_reply": "2025-01-22T04:39:48.653300Z"
    },
    "papermill": {
     "duration": 22.093016,
     "end_time": "2025-01-22T04:39:48.655873",
     "exception": false,
     "start_time": "2025-01-22T04:39:26.562857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Correct tokenizer initialization\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "# Ensure pad_token is set correctly\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Keep the model instantiation as is\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f4ca99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:48.665113Z",
     "iopub.status.busy": "2025-01-22T04:39:48.664852Z",
     "iopub.status.idle": "2025-01-22T04:39:48.671593Z",
     "shell.execute_reply": "2025-01-22T04:39:48.670807Z"
    },
    "papermill": {
     "duration": 0.013161,
     "end_time": "2025-01-22T04:39:48.673186",
     "exception": false,
     "start_time": "2025-01-22T04:39:48.660025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ade9df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:48.681697Z",
     "iopub.status.busy": "2025-01-22T04:39:48.681438Z",
     "iopub.status.idle": "2025-01-22T04:39:48.684928Z",
     "shell.execute_reply": "2025-01-22T04:39:48.684259Z"
    },
    "papermill": {
     "duration": 0.009549,
     "end_time": "2025-01-22T04:39:48.686586",
     "exception": false,
     "start_time": "2025-01-22T04:39:48.677037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     base_model,\n",
    "#     quantization_config=bnb_config,\n",
    "#     device_map=\"auto\",\n",
    "#     attn_implementation=attn_implementation\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1ad88",
   "metadata": {
    "papermill": {
     "duration": 0.003777,
     "end_time": "2025-01-22T04:39:48.694194",
     "exception": false,
     "start_time": "2025-01-22T04:39:48.690417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Before fine-tuning with the drug labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c281917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:48.702455Z",
     "iopub.status.busy": "2025-01-22T04:39:48.702210Z",
     "iopub.status.idle": "2025-01-22T04:39:48.705531Z",
     "shell.execute_reply": "2025-01-22T04:39:48.704799Z"
    },
    "papermill": {
     "duration": 0.009134,
     "end_time": "2025-01-22T04:39:48.707037",
     "exception": false,
     "start_time": "2025-01-22T04:39:48.697903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pipe = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     torch_dtype=torch_dtype,\n",
    "#     device_map=\"auto\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be940b1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:48.716575Z",
     "iopub.status.busy": "2025-01-22T04:39:48.716327Z",
     "iopub.status.idle": "2025-01-22T04:39:48.719747Z",
     "shell.execute_reply": "2025-01-22T04:39:48.719069Z"
    },
    "papermill": {
     "duration": 0.009422,
     "end_time": "2025-01-22T04:39:48.721249",
     "exception": false,
     "start_time": "2025-01-22T04:39:48.711827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input_data = {\n",
    "#   \"brand_name\": \"PRISMASOL BGK2/0\",\n",
    "#   \"generic_name\": \"MAGNESIUM CHLORIDE, DEXTROSE MONOHYDRATE, LACTIC ACID, SODIUM CHLORIDE, SODIUM BICARBONATE AND POTASSIUM CHLORIDE\",\n",
    "#   \"query\": \"Does the drug PRISMASOL BGK2/0 have any adverse reactions?\"\n",
    "# }\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": f\"Brand Name: {input_data['brand_name']}\\nGeneric Name: {input_data['generic_name']}\\n\\nQuery: {input_data['query']}\"}\n",
    "# ]\n",
    "# messages = [{\"role\": \"system\", \"content\": \"You are a helpful medical assistant.\"}] + messages\n",
    "\n",
    "# prompt = tokenizer.apply_chat_template(\n",
    "#     messages, tokenize=False, add_generation_prompt=True\n",
    "# )\n",
    "\n",
    "# outputs = pipe(prompt, max_new_tokens=1000, do_sample=True)\n",
    "\n",
    "# print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95e55042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:48.729658Z",
     "iopub.status.busy": "2025-01-22T04:39:48.729396Z",
     "iopub.status.idle": "2025-01-22T04:39:48.733009Z",
     "shell.execute_reply": "2025-01-22T04:39:48.732311Z"
    },
    "papermill": {
     "duration": 0.009545,
     "end_time": "2025-01-22T04:39:48.734610",
     "exception": false,
     "start_time": "2025-01-22T04:39:48.725065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "#     Expected Adverse Reaction:\n",
    "# '''\n",
    "# expected = {\n",
    "#     \"adverse_reactions\": [\n",
    "#         \"6 ADVERSE REACTIONS The following adverse reactions have been identified during postapproval use with these or other similar products and therefore may occur with use of PHOXILLUM or PRISMASOL. Because these reactions are reported voluntarily from a population of uncertain size, it is not always possible to reliably estimate their frequency or establish a causal relationship to drug exposure. \\u2022 Metabolic acidosis \\u2022 Hypotension \\u2022 Acid-base disorders \\u2022 Electrolyte imbalance including calcium ionized increased (reported in PRISMASOL solutions containing calcium), hyperphosphatemia, and hypophosphatemia \\u2022 Fluid imbalance\"\n",
    "#       ],\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ee462",
   "metadata": {
    "papermill": {
     "duration": 0.003488,
     "end_time": "2025-01-22T04:39:48.741890",
     "exception": false,
     "start_time": "2025-01-22T04:39:48.738402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Adverse Reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5c7e632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:48.750140Z",
     "iopub.status.busy": "2025-01-22T04:39:48.749939Z",
     "iopub.status.idle": "2025-01-22T04:39:49.003799Z",
     "shell.execute_reply": "2025-01-22T04:39:49.003114Z"
    },
    "papermill": {
     "duration": 0.260051,
     "end_time": "2025-01-22T04:39:49.005728",
     "exception": false,
     "start_time": "2025-01-22T04:39:48.745677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, PeftType, TaskType\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],  # Adapt to your model's architecture\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Apply PEFT to the model\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49cfd0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:39:49.014821Z",
     "iopub.status.busy": "2025-01-22T04:39:49.014592Z",
     "iopub.status.idle": "2025-01-22T04:40:49.209561Z",
     "shell.execute_reply": "2025-01-22T04:40:49.208604Z"
    },
    "papermill": {
     "duration": 60.205157,
     "end_time": "2025-01-22T04:40:49.214932",
     "exception": false,
     "start_time": "2025-01-22T04:39:49.009775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c5907662104ba0924c3603805c5668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67610e0ee423439ba9d0d59046ecb4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27901 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = \"/kaggle/input/adr-dataset-v1/adverse_reactions_dataset.json\"\n",
    "\n",
    "dataset = load_dataset('json', data_files=dataset_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    inputs = [\n",
    "        f\"Input: {input_text} Response: {response_text}\"\n",
    "        for input_text, response_text in zip(examples[\"input_text\"], examples[\"response_text\"])\n",
    "    ]\n",
    "    # Tokenize\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing\n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6997e24d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:40:49.224267Z",
     "iopub.status.busy": "2025-01-22T04:40:49.224025Z",
     "iopub.status.idle": "2025-01-22T04:40:49.228481Z",
     "shell.execute_reply": "2025-01-22T04:40:49.227642Z"
    },
    "papermill": {
     "duration": 0.011101,
     "end_time": "2025-01-22T04:40:49.230241",
     "exception": false,
     "start_time": "2025-01-22T04:40:49.219140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131072\n"
     ]
    }
   ],
   "source": [
    "print(model.config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4391906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:40:49.239798Z",
     "iopub.status.busy": "2025-01-22T04:40:49.239053Z",
     "iopub.status.idle": "2025-01-22T04:40:49.272587Z",
     "shell.execute_reply": "2025-01-22T04:40:49.271915Z"
    },
    "papermill": {
     "duration": 0.039813,
     "end_time": "2025-01-22T04:40:49.274312",
     "exception": false,
     "start_time": "2025-01-22T04:40:49.234499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "batch_size = 2\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32d4119d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:40:49.283352Z",
     "iopub.status.busy": "2025-01-22T04:40:49.283122Z",
     "iopub.status.idle": "2025-01-22T04:40:49.323462Z",
     "shell.execute_reply": "2025-01-22T04:40:49.322599Z"
    },
    "papermill": {
     "duration": 0.04672,
     "end_time": "2025-01-22T04:40:49.325135",
     "exception": false,
     "start_time": "2025-01-22T04:40:49.278415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_split_ratio = 0.8\n",
    "train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(int(len(tokenized_dataset[\"train\"]) * train_test_split_ratio)))\n",
    "eval_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(int(len(tokenized_dataset[\"train\"]) * train_test_split_ratio), len(tokenized_dataset[\"train\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4399ece9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T04:40:49.334907Z",
     "iopub.status.busy": "2025-01-22T04:40:49.334291Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-01-22T04:40:49.329248",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/3059566337.py:7: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msrahman212074\u001b[0m (\u001b[33msrahman212074-united-international-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.19.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250122_044050-4lu3chm9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./results\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/srahman212074-united-international-university/huggingface\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/srahman212074-united-international-university/huggingface/runs/4lu3chm9\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7342' max='8370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7342/8370 11:56:59 < 1:40:25, 0.17 it/s, Epoch 2.63/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.765176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.649600</td>\n",
       "      <td>0.638570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Set up the wandb API key\n",
    "wandb.login(key=\"06c879c1f279e5d9818d493d85486dc08f5d2cf3\")\n",
    "\n",
    "# Then initialize the trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d819d374",
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-22T04:38:01.426Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(\"llamaDrugLabel++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62dbf59",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca838e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6524233,
     "sourceId": 10544633,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 121027,
     "modelInstanceId": 100933,
     "sourceId": 120002,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 121027,
     "modelInstanceId": 100936,
     "sourceId": 120005,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-22T04:38:18.517012",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}